{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SdI.04 - Sklearn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Il modulo `sklearn`\n",
        "\n",
        "Framework basato su `numpy` (compatibile con `pandas`, `matplotlib` e `seaborn`) che permette di \"allenare\" e testare modelli per **machine learning**. Alcuni di questi modelli sono\n",
        "\n",
        "* regressione (lineare e con *feature transformation*);\n",
        "* alberi decisionali e *random forest*\n",
        "* clustering ($k$-means, clustering gerarchico, ...)\n",
        "* reti neurali (non *deep*, ma *shallow*)\n",
        "* ...\n",
        "\n",
        "Vi mostrerò qualcuno (due o tre) di questi modelli oltre che introdure la *pipeline* di utilizzo\n",
        "\n",
        "    Dati -> Pre-proc -> Training -> Testing\n",
        "\n",
        "**Attenzione** Sebbene `sklearn` contenga il codice per utilizzare *reti neurali*, non va utilizzato per *deep learning*. Per quello ci sono altre librerie (`opencv`, `tensorflow`, ...) di cui, purtroppo, non ho tempo di occuparmi in questo ciclo di seminari.\n",
        "\n"
      ],
      "metadata": {
        "id": "gIeRt3Ed7CRq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-DbNUJTbLtS3"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_wine\n",
        "data = load_wine(as_frame=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = data.frame"
      ],
      "metadata": {
        "id": "Ig-0xLZOLz35"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Un po' di \"teoria\" sul *machine learning*\n",
        "Ci sono tre tipi principali di tecniche di machine learning:\n",
        "\n",
        "* **supervised** learning\n",
        "* **unsupervised** learning\n",
        "* **reinforcment** learning\n",
        "\n",
        "Tempo permettendo, vedremo esempi del primo e del secondo tipo. \n",
        "\n",
        "L'idea è che i dati contengono le informazioni, ma imparare troppo bene i dati può essere un problema (**overfitting**). Si può mostrare matematicamente che, nella maggior parte dei casi, i dati usati nel *training* devono essere diversi da quelli usati nel *testing*\n",
        "\n"
      ],
      "metadata": {
        "id": "Lepmr5urjaS8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Passo 0: scelta di $X$ e $Y$\n",
        "Una volta che abbiamo un dataset dobbiamo decidere quale saranno i **predittori** (o *feature*) $x_1,x_2,\\ldots,x_m$ e quale (quali) sarà (saranno) le (le) varaibile (variabili) dipendenti o **target** $y_1,\\ldots,y_p$."
      ],
      "metadata": {
        "id": "74RTMVfrlxEk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y = df\n",
        "X = df"
      ],
      "metadata": {
        "id": "5wLm_lIBmbRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Passo 1: split train e test\n",
        "Operazione talmente frquente che in `sklearn` ci sono metodi apposta, vediamo il tipico caso in cui un 80% casuale dei dati si usa per il training ed il restante 20% per il testing.\n",
        "\n",
        "* Più campioni si uasno per il training meglio sarà il modello ma...\n",
        "* ...meno campioni si usano per il testing meno sarà affidabile la stima dell'errore."
      ],
      "metadata": {
        "id": "sGIjk9bRlwcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "hRjgyTSRMjiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iLgShOlhkgvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Passo 2: Training\n",
        "\n",
        "1. Si sceglie che modello usare: regressione, *decision tree*, *neural network*, ...\n",
        "2. Si crea un modello **usando solo il training set**\n",
        "3. Si misura la bontà del modello facendo predizione sul test set\n",
        "\n",
        "Importante\n",
        "$$ X_{train} \\cap X_{test} = \\emptyset $$\n",
        "così funziona `train_test_split`."
      ],
      "metadata": {
        "id": "unWBYmLrk__s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "09ZOh8dTmtDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Decision Tree e Random Forest"
      ],
      "metadata": {
        "id": "JMVAVjBSmtpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.tree\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "f20U5nQBlefW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Clustering"
      ],
      "metadata": {
        "id": "stgbISolmxF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans"
      ],
      "metadata": {
        "id": "YAtRbQdmmzmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### $k$-Nearest Neighbour ($k$-NN)"
      ],
      "metadata": {
        "id": "wYy2vHW_mz8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import NearestNeighbors"
      ],
      "metadata": {
        "id": "zGz_Yyprm4Oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####"
      ],
      "metadata": {
        "id": "MdDGLMPYm4xU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (Shallow) Neural Network"
      ],
      "metadata": {
        "id": "-aNZ-lPbm7TD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier"
      ],
      "metadata": {
        "id": "SOWGlzu0m-ZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classificazione vs Regressione"
      ],
      "metadata": {
        "id": "_s_CiVnCnI0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "f5hDs0TfnLrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overfitting e $k$-Fold Cross-Validation"
      ],
      "metadata": {
        "id": "mw_RdVm2oWQP"
      }
    }
  ]
}